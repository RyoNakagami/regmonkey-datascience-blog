---
title: "Law of Large Numbers"
author: "Ryo Nakagami"
date: "2025-07-08"
date-modified: "2025-07-08"
categories: [統計]
listing_category: datascience-statistics-series
comments:
  utterances:
       repo: RyoNakagami/regmonkey-datascience-blog
       label: discussion
       issue-term: title
---

## Review Question

::: {#exr- .custom_problem .blog-custom-border}
[WLLN]{.def-title}

$|m|< \infty, |\sigma| < \infty$ として $X_i \overset{\mathrm{iid}}{\sim} D(m, \sigma^2)$ とする．このとき任意の $\epsilon > 0$ について，

$$
\lim_{n\to\infty} P\left[\left|\frac{X_1 + \cdots + X_n}{n} - m\right| > \epsilon\right] = 0
$$

が成り立つ．

:::

::: {.callout-note collapse="false" icon=false}
## Proof

$Z \equiv \sum X_i$ とおくと，i.i.d の仮定より

$$
\begin{align}
\mathbb E[Z] &= nm\\
\operatorname{Var}(Z) &= n\sigma^2
\end{align}
$$

よって，

$$
\begin{align}
P\bigg[\bigg|\frac{Z}{n} - m\bigg| > \epsilon\bigg]
  &= P[|Z - nm| > n\epsilon]\\
  &= P[(Z - nm)^2 > n^2\epsilon^2]\\
  &\leq \frac{\mathbb E[(Z - nm)^2]}{n^2\epsilon^2} \, \ \because{\text{Markov不等式}}\\
  &= \frac{\sigma^2}{n\epsilon^2}
\end{align}
$$

従って，

$$
\lim_{n\to\infty} P\left[\left|\frac{X_1 + \cdots + X_n}{n} - m\right| > \epsilon\right] = 0
$$


:::

## The Weak Law of Large Numbers

::: {#thm- .custom_problem .blog-custom-border}
[The Weak Law of Large Numbers]{.def-title}

$X_i$ がi.i.d.にmean $\mu$ の分布に従うとする．このとき，任意の $\epsilon >0$ について

$$
\lim_{n\to\infty} P\left[\left|\frac{X_1 + \cdots + X_n}{n} - \mu\right| > \epsilon\right] = 0
$$

:::

- WLLNは，$n$ が十分大きいとき，標本平均の分布の大部分が母平均 $\mu$ の近くに集中することを示しています
- $\mu$ を中心とした長さのある正の区間 $[\mu−\epsilon, \mu+\epsilon]$ を考えると、$\frac{\sum X_i}{N}$ がその区間内に入る確率は高い


::: {#exm- .custom_problem }
[conservativeな出口調査推定]{.def-title}

有権者の内，$p$ の割合がA党を支持しているとします．$n$ 人を"randomly selected"して，その結果 $M_n$ の割合の人がA等を支持していたとします．マルコフ不等式より

$$
P(|M_n - p|>\epsilon)\leq \frac{p(1-p)}{n\epsilon^2}
$$

$p(1-p)\leq \frac{1}{4}$ から保守的に見積もると

$$
P(|M_n - p|>\epsilon)\leq \frac{1}{4n\epsilon^2}
$$

例として $\epsilon =0.01, n=50,000$ の水準を考えると

$$
P(|M_n - p|>\epsilon)\leq \frac{1}{4\cdot 10,000\cdot 0.01^2} = 0.05
$$

つまり，$n=50,000$ インタビューしてようやく誤差 $0.01$ 未満の水準となることがわかります．

::: {.callout-tip}
### REMARKS

- CLTを用いるともっと少ないサンプルサイズ $n$ で誤差 $0.01$ 未満の水準を達成できます

:::

:::
***

## The Strong Law of Large Numbers

::: {#thm- .custom_problem .blog-custom-border}
[The Strong Law of Large Numbers]{.def-title}

$X_i$ がi.i.d.にmean $\mu$ の分布に従うとする．また，$\mathbb E[|X_i|] < \infty$ であるとする．このとき，sample mean列 

$$
M_n = \frac{X_1 + \cdots + X_n}{n}
$$

について

$$
P\left(\lim_{n\to\infty}\frac{X_1 + \cdots + X_n}{n} = \mu\right) = 1
$$

が成り立つことを強大数の法則という．これはつまり，

$$
M_n \overset{a.s.}{\to} \mu
$$


:::


### ボレル＝カンテリの補題

::: {#thm-borel-1st .custom_problem  .blog-custom-border}
[ボレル＝カンテリの補題 I]{.def-title}

$(\Omega, \mathcal{F}, P)$ を確率空間とするとき，$A_i \in \mathcal{F}$ に対して，

$$
\sum_{i=1}^\infty P(A_i) < \infty \Rightarrow P(\underset{n\to\infty}{\lim\sup} A_n) = 0
$$

:::

::: {.callout-note collapse="false" icon=false}
## Proof

上極限の定義と確率の劣加法性より，

$$
\begin{align}
P(\underset{n\to\infty}{\lim\sup} A_n)
  &= P\left(\bigcap_{n=1}^\infty\bigcup_{k=n}^\infty A_k\right)\\
  &= \lim_{n\to\infty} P\left(\bigcup_{k=n}^\infty A_k\right)\\
  &\leq \lim_{n}\sum_{k=n}^\infty P(A_k)
\end{align}
$$

ここで，$\sum_{i=1}^\infty P(A_i)$ であるので，$\displaystyle\lim_{n}\sum_{k=n}^\infty P(A_k) = 0$. 従って，

$$
\sum_{i=1}^\infty P(A_i) < \infty \Rightarrow P(\underset{n\to\infty}{\lim\sup} A_n) = 0
$$

:::

@thm-borel-1st は $(A_i)_{i\in\mathbb N}$ のうち高々有限個の $A_i$ しか起こらないことを意味します．また，書き換えると

$$
P(\underset{n\to\infty}{\lim\sup} A_n) = 0 \Leftrightarrow P(\underset{n\to\infty}{\lim\inf} A^c_n)= 1
$$

::: {#exm- .custom_problem }
[コイン投げ問題とボレル＝カンテリの補題 I]{.def-title}

コインを何度も独立に投げる試行を考えます．ただし，毎回投げるコインは違いものとし，$n$ 回目に投げるコインの表の出る確率は

$$
p_n \in (0, 1)
$$

とします．このとき，ボレル＝カンテリの補題 Iより

$$
\sum_{n=1}^\infty p_n < \infty \Rightarrow P(\text{表が出る回数は有限回}) = 1
$$

となります．（$\sum_{n=1}^\infty p_n < \infty$ の一例としてはバーゼル問題など参照） 

例として，確率変数

$$
X_n = \left\{\begin{array}{c}
1 & \text{$n$回目に表が出る}\\
0 & \text{$n$回目に裏が出る}
\end{array}\right.
$$

として，$A_n = \{X_n = 1\} \in \mathcal{F}$ を考えると，

$$
\sum_{n=1}^\infty P(A_n) = \sum_{n=1}^\infty p_n < \infty
$$

ボレル=カンテリの補題 I を用いると

$$
P(\underset{n\to\infty}{\lim\inf} A^c_n) = P\left(\lim_{n\to\infty}\bigcup_{n=1}^\infty\bigcap_{k=n}^\infty\{X_n = 0\} \right) =  1
$$

これは，確率1で，ある $n = N$ が存在して $k\geq n$ に対して $\{X_n = 0\}$, つまり裏が出るということを意味します．これは，表が出る回数は有限回と同じ意味です．

:::
***

::: {#thm- .custom_problem  .blog-custom-border}
[Almost surely convergence]{.def-title}

確率変数列 $\{X_n\}$ について，任意の $\epsilon >0$ に対して

$$
\sum_{n=1}^\infty P(|X_n - X| > \epsilon) < \infty
$$

を満たすとします．このとき，

$$
X_n \overset{\text{a.s.}}{\to}X
$$

:::

::: {.callout-note collapse="false" icon=false}
## Proof

任意の $p \in \mathbb N$ に対して，確率事象を

$$
A_n^p = \{|X_n - X| > p^{-1}\}
$$

とおきます．仮定より

$$
\sum_{n=1}^\infty P(A_n^p) < \infty
$$

であるので，ボレル=カンテリの補題 I を用いると，任意の $p \in \mathbb N$ に対して

$$
P\left(\underset{n\to\infty}{\lim\sup} A_n^p \right) = 0 \Leftrightarrow P\left(\underset{n\to\infty}{\lim\inf} (A_n^p)^c \right) = 1
$$

任意の $p\in\mathbb N$ で成立することから

$$
\begin{align}
1
  &= P\left(\bigcap_{p=1}^\infty \left\{\underset{n\to\infty}{\lim\inf} (A_n^p)^c\right\} \right)\\
  &= P\left(\bigcap_{p=1}^\infty\bigcup_{n=1}^\infty\bigcap_{k\geq n} (A_k^p)^c\right)\\
  &= P\left(\bigcap_{p=1}^\infty\bigcup_{n=1}^\infty\bigcap_{k\geq n} \{|X_k - X| \leq p^{-1}\}\right)
\end{align}
$$

$\epsilon = p^{-1}$ と対応させると，任意の $\epsilon >0$ にたいして，ある $n\in\mathbb N$ が存在して，$k\geq n$ となるすべての $k$ について，

$$
|X_k - X| \leq \epsilon
$$

となる確率が１である，ことを意味しており，これは概収束の定義と一致している．

:::