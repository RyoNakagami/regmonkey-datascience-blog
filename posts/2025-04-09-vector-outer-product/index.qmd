---
title: "ベクトル空間における外積"
author: "Ryo Nakagami"
date: "2025-04-09"
categories: [線形代数]
listing_category: math-general
comments:
  utterances:
       repo: RyoNakagami/regmonkey-datascience-blog
       label: discussion
       issue-term: title
---

<strong > &#9654;&nbsp; Key Takeaways</strong>

- ３次元空間特有のベクトルの積として外積がある

## ベクトルの外積

<div class="blog-custom-border" style="margin-top: 1rem; margin-bottom: 1rem;">
::: {#def-outer-product .custom_problem }
**: 外積**
<br>

３次元実数空間のベクトル 

$$
\begin{align}
\pmb a = (a_1, a_2, a_3)\\
\pmb b = (b_1, b_2, b_3)
\end{align}
$$

に対して，

$$
\left(\begin{vmatrix}
a_2 & a_3\\
b_2 & b_3
\end{vmatrix},
- \begin{vmatrix}
a_1 & a_3\\
b_1 & b_3
\end{vmatrix},
\begin{vmatrix}
a_1 & a_2\\
b_1 & b_2
\end{vmatrix}
\right)
$$

を $\pmb a$ と $\pmb b$ の外積またはベクトル積 といい，$\pmb a \times \pmb b$ と表す．

:::

</div>

3次元実ベクトル空間 $\mathbb R^3$ の標準基低

$$
\pmb e_1 = (1, 0, 0), \pmb e_2 = (0, 1, 0), \pmb e_3 = (0, 0, 1)
$$

を用いて表現すると

$$
\pmb a \times \pmb b = \begin{vmatrix}
a_2 & a_3\\
b_2 & b_3
\end{vmatrix}\pmb e_1
- \begin{vmatrix}
a_1 & a_3\\
b_1 & b_3
\end{vmatrix}\pmb e_2 +
\begin{vmatrix}
a_1 & a_2\\
b_1 & b_2
\end{vmatrix}\pmb e_3
$$

と表現することもできます．この式を直感的に理解するとすると

$$
\begin{vmatrix}
\pmb e_1& \pmb e_2 & \pmb e_3\\
a_1& a_2 & a_3\\
b_1& b_2 & b_3
\end{vmatrix}
$$

と対応すると考えることもできます．

:::{.callout-note}
## Property: 外積の性質

外積について次の法則が成り立つ

$$
\begin{align}
&\pmb a \times \pmb b = -\pmb b\times \pmb a\\
&(\lambda\pmb a) \times \pmb b = \pmb a \times (\lambda \pmb b ) = \lambda (\pmb a \times \pmb b )\\
&\pmb a \times (\pmb b  + \pmb c) = \pmb a \times \pmb b + \pmb a \times \pmb c\\
&\pmb a \times \pmb a = \pmb 0 
\end{align}
$$

:::

<!--::: {.callout-note collapse="true" icon=false}-->
::: {.callout-note collapse="false" icon=false}
## Proof

<strong > &#9654;&nbsp;$\pmb a \times \pmb b = -\pmb b \times \pmb a$</strong>

$$
\begin{align}
\pmb a \times \pmb b
    &= \begin{vmatrix}
a_2 & a_3\\
b_2 & b_3
\end{vmatrix}\pmb e_1
- \begin{vmatrix}
a_1 & a_3\\
b_1 & b_3
\end{vmatrix}\pmb e_2 +
\begin{vmatrix}
a_1 & a_2\\
b_1 & b_2
\end{vmatrix}\pmb e_3\\
&= -\begin{vmatrix}
b_2 & b_3\\
a_2 & a_3
\end{vmatrix}\pmb e_1
+ \begin{vmatrix}
b_1 & b_3\\
a_1 & a_3
\end{vmatrix}\pmb e_2 -
\begin{vmatrix}
b_1 & b_2\\
a_1 & a_2
\end{vmatrix}\pmb e_3\\
&= (-1)\left(
\begin{vmatrix}
b_2 & b_3\\
a_2 & a_3
\end{vmatrix}\pmb e_1
- \begin{vmatrix}
b_1 & b_3\\
a_1 & a_3
\end{vmatrix}\pmb e_2 +
\begin{vmatrix}
b_1 & b_2\\
a_1 & a_2
\end{vmatrix}\pmb e_3\right)\\
&= - \pmb b \times \pmb a
\end{align}
$$

<strong > &#9654;&nbsp; $(\lambda\pmb a) \times \pmb b = \pmb a \times (\lambda \pmb b ) = \lambda (\pmb a \times \pmb b )$</strong>

\eqref{#eq-determinant-linear} より

$$
\begin{align}
(\lambda\pmb a) \times \pmb b 
    &= \begin{vmatrix}
\lambda a_2 & \lambda a_3\\
b_2 & b_3
\end{vmatrix}\pmb e_1
- \begin{vmatrix}
\lambda a_1 & \lambda a_3\\
b_1 & b_3
\end{vmatrix}\pmb e_2 +
\begin{vmatrix}
\lambda a_1 & \lambda a_2\\
b_1 & b_2
\end{vmatrix}\pmb e_3\\
&= \lambda\begin{vmatrix}
a_2 & a_3\\
b_2 & b_3
\end{vmatrix}\pmb e_1
- \lambda\begin{vmatrix}
a_1 & a_3\\
b_1 & b_3
\end{vmatrix}\pmb e_2 +
\lambda\begin{vmatrix}
a_1 & a_2\\
b_1 & b_2
\end{vmatrix}\pmb e_3\\
&= \lambda (\pmb a\times \pmb b )
\end{align}
$$

同様に

$$
\begin{align}
\pmb a\times (\lambda\pmb b)  
    &= \begin{vmatrix}
a_2 & a_3\\
\lambda b_2 & \lambda b_3
\end{vmatrix}\pmb e_1
- \begin{vmatrix}
a_1 & a_3\\
\lambda b_1 & \lambda b_3
\end{vmatrix}\pmb e_2 +
\begin{vmatrix}
a_1 & a_2\\
\lambda b_1 & \lambda b_2
\end{vmatrix}\pmb e_3\\
&= \lambda\begin{vmatrix}
a_2 & a_3\\
b_2 & b_3
\end{vmatrix}\pmb e_1
- \lambda\begin{vmatrix}
a_1 & a_3\\
b_1 & b_3
\end{vmatrix}\pmb e_2 +
\lambda\begin{vmatrix}
a_1 & a_2\\
b_1 & b_2
\end{vmatrix}\pmb e_3\\
&= \lambda (\pmb a\times \pmb b )
\end{align}
$$

<strong > &#9654;&nbsp; $\pmb a \times (\pmb b  + \pmb c) = \pmb a \times \pmb b + \pmb a \times \pmb c$</strong>

$$
\begin{align}
&\pmb a\times (\pmb b + \pmb c)\\
    &=
        \begin{vmatrix}
        a_2 & a_3\\
        b_2 + c_2 &  b_3 + c_3
        \end{vmatrix}\pmb e_1
        - \begin{vmatrix}
        a_1 & a_3\\
         b_1 + c_1 &  b_3 + c_3
        \end{vmatrix}\pmb e_2 +
        \begin{vmatrix}
        a_1 & a_2\\
         b_1 + c_1 &  b_2 + c_2
        \end{vmatrix}\pmb e_3\\
    &=
        \left(
            \begin{vmatrix}
            a_2 & a_3\\
            b_2&  b_3
            \end{vmatrix}
            +
            \begin{vmatrix}
            a_2 & a_3\\
            c_2&  c_3
            \end{vmatrix}
        \right)\pmb e_1
        - \left(
            \begin{vmatrix}
            a_1 & a_3\\
            b_1&  b_3
            \end{vmatrix}
            +
            \begin{vmatrix}
            a_1 & a_3\\
            c_1&  c_3
            \end{vmatrix}
        \right)\pmb e_2 +
        \left(
            \begin{vmatrix}
            a_1 & a_2\\
            b_1&  b_2
            \end{vmatrix}
            +
            \begin{vmatrix}
            a_1 & a_2\\
            c_1&  c_2
            \end{vmatrix}
        \right)\pmb e_3\\
    &= \left(
            \begin{vmatrix}
            a_2 & a_3\\
            b_2&  b_3
            \end{vmatrix}
        \pmb e_1
        - 
            \begin{vmatrix}
            a_1 & a_3\\
            b_1&  b_3
            \end{vmatrix}
            \pmb e_2 +
            \begin{vmatrix}
            a_1 & a_2\\
            b_1&  b_2
            \end{vmatrix}
       \pmb e_3\right)+
       \left(
            \begin{vmatrix}
            a_2 & a_3\\
            c_2&  c_3
            \end{vmatrix}
        \pmb e_1
        - 
            \begin{vmatrix}
            a_1 & a_3\\
            c_1&  c_3
            \end{vmatrix}
            \pmb e_2 +
            \begin{vmatrix}
            a_1 & a_2\\
            c_1&  c_2
            \end{vmatrix}
       \pmb e_3\right)\\
    &= \pmb a \times \pmb b + \pmb a \times \pmb c
\end{align}
$$




<strong > &#9654;&nbsp; $\pmb a\times \pmb a = \pmb 0$</strong>

$$
\begin{align}
\pmb a \times \pmb a 
    &= \begin{vmatrix}
a_2 & a_3\\
a_2 & a_3
\end{vmatrix}\pmb e_1
- \begin{vmatrix}
a_1 & a_3\\
a_1 & a_3
\end{vmatrix}\pmb e_2 +
\begin{vmatrix}
a_1 & a_2\\
a_1 & a_2
\end{vmatrix}\pmb e_3\\
&= 0\pmb e_1 - 0\pmb e_2 + 0\pmb e_3\\
&= \pmb 0
\end{align}
$$

:::

::: {#exm- .custom_problem }
<br>

$\mathbb R^3$ の標準基底 $\pmb e_1, \pmb e_2, \pmb e_3$ に関して

$$
\begin{align}
\pmb e_1 \times \pmb e_2 &= \left(\begin{vmatrix}
 0 & 0\\
 1 & 0
\end{vmatrix}, -\begin{vmatrix}
1  & 0\\
0  & 0
\end{vmatrix}, \begin{vmatrix}
1 & 0 \\
0 & 1 
\end{vmatrix} \right)\\
&= \pmb e_3
\end{align}
$$

$$
\begin{align}
\pmb e_2 \times \pmb e_3 &= \left(\begin{vmatrix}
 1 & 0\\
 0 & 1
\end{vmatrix}, -\begin{vmatrix}
0  & 0\\
0  & 1
\end{vmatrix}, \begin{vmatrix}
0 & 1 \\
0 & 0 
\end{vmatrix} \right)\\
&= \pmb e_1
\end{align}
$$

$$
\begin{align}
\pmb e_3 \times \pmb e_1 &= \left(\begin{vmatrix}
 0 & 1\\
 0 & 0
\end{vmatrix}, -\begin{vmatrix}
0  & 1\\
1  & 0
\end{vmatrix}, \begin{vmatrix}
0 & 0 \\
1 & 0 
\end{vmatrix} \right)\\
&= \pmb e_2
\end{align}
$$

:::
---

<strong > &#9654;&nbsp; 内積と外積を組み合わせた性質</strong>

<div class="blog-custom-border" style="margin-top: 1rem; margin-bottom: 1rem;">
::: {#thm- .custom_problem }
<br>

３つのベクトル $\pmb a = (a_1, a_2, a_3), \pmb b = (b_1, b_2, b_3), \pmb c = (c_1, c_2, c_3)$ について，

$$
(\pmb a\times \pmb b, \pmb c) = (\pmb a, \pmb b \times \pmb c) = \begin{vmatrix}
a_1 & a_2 & a_3\\
b_1 & b_2 & b_3\\
c_1 & c_2 & c_3
\end{vmatrix}
$$

:::

</div>

<!--::: {.callout-note collapse="true" icon=false}-->
::: {.callout-note collapse="false" icon=false}
## Proof

$$
\begin{align}
(\pmb a\times \pmb b, \pmb c)
    &= 
        \left(\begin{vmatrix}
        a_2 & a_3\\
        b_2 & b_3
        \end{vmatrix}\pmb e_1
        - \begin{vmatrix}
        a_1 & a_3\\
        b_1 & b_3
        \end{vmatrix}\pmb e_2 +
        \begin{vmatrix}
        a_1 & a_2\\
        b_1 & b_2
        \end{vmatrix}\pmb e_3, \pmb c\right)\\
    &=
    \begin{vmatrix}
        a_2 & a_3\\
        b_2 & b_3
        \end{vmatrix}c_1
        - \begin{vmatrix}
        a_1 & a_3\\
        b_1 & b_3
        \end{vmatrix}c_2 +
        \begin{vmatrix}
        a_1 & a_2\\
        b_1 & b_2
        \end{vmatrix}c_3\\
    &= 
    \begin{vmatrix}
a_1 & a_2 & a_3\\
b_1 & b_2 & b_3\\
c_1 & c_2 & c_3
\end{vmatrix}
\end{align}
$$

同様に

$$
\begin{align}
(\pmb a, \pmb b \times \pmb c)
&= (\pmb b \times \pmb c, \pmb a)\\
    &= 
        \left(\begin{vmatrix}
        b_2 & b_3\\
        c_2 & c_3
        \end{vmatrix}\pmb e_1
        - \begin{vmatrix}
        b_1 & b_3\\
        c_1 & c_3
        \end{vmatrix}\pmb e_2 +
        \begin{vmatrix}
        b_1 & b_2\\
        c_1 & c_2
        \end{vmatrix}\pmb e_3, \pmb a\right)\\
    &=
        \begin{vmatrix}
        b_2 & b_3\\
        c_2 & c_3
        \end{vmatrix}a_1
        - \begin{vmatrix}
        b_1 & b_3\\
        c_1 & c_3
        \end{vmatrix}a_2 +
        \begin{vmatrix}
        b_1 & b_2\\
        c_1 & c_2
        \end{vmatrix} a_3\\
    &= 
    \begin{vmatrix}
a_1 & a_2 & a_3\\
b_1 & b_2 & b_3\\
c_1 & c_2 & c_3
\end{vmatrix}
\end{align}
$$

:::


## 外積の幾何学的性質

<div class="blog-custom-border" style="margin-top: 1rem; margin-bottom: 1rem;">
::: {#thm- .custom_problem }
<br>

３次元実ベクトル $\pmb a, \pmb b$ の外積の大きさは

$$
||\pmb a\times \pmb b|| = ||\pmb a||\,||\pmb b||\sin \theta
$$

ここで， $\theta$ は $\pmb a, \pmb b$ のなす角であるとする


:::

</div>

::: {.callout-note collapse="false" icon=false}
## Proof

$$
\begin{align}
||\pmb a\times \pmb b|| = ((a_2b_3 - a_3b_2), -(a_1b_3 - a_3b_1), (a_1b_2 - a_2b_1)) 
\end{align}
$$

であるので

$$
\begin{align}
||\pmb a\times \pmb b||^2
    =& a_2^2b_3^2 + a_3^2b_2^2 + a_1^2b_3^2 + a_3^2b_1^2 + a_1^2b_2^2 + a_2^2b_1^2\\
     & - 2(a_2a_3b_2b_3 + a_1a_3b_1b_3+ a_1a_2b_1b_2) 
\end{align}
$$

続いて

$$
\cos\theta = \frac{(\pmb a, \pmb b)}{||\pmb a||\,||\pmb b||}\quad \text{s.t. } (0\leq \theta \leq \pi)
$$

であることから

$$
\begin{align}
||\pmb a||^2\,||\pmb b||^2\sin^2\theta
    =& ||\pmb a||^2\,||\pmb b||^2 (1 - \cos^2\theta)\\
    =& ||\pmb a||^2\,||\pmb b||^2 - (\pmb a, \pmb b)^2\\
    =& (a_1^2 + a_2^2 + a_3^2)(b_1^2 + b_2^2 + b_3^2) - (a_1b_1 + a_2b_2 + a_3b_3)^2\\
    =& a_2^2b_3^2 + a_3^2b_2^2 + a_1^2b_3^2 + a_3^2b_1^2 + a_1^2b_2^2 + a_2^2b_1^2\\
     & - 2(a_2a_3b_2b_3 + a_1a_3b_1b_3+ a_1a_2b_1b_2) 
\end{align}
$$


従って，

$$
||\pmb a\times \pmb b||^2 = ||\pmb a||^2\,||\pmb b||^2\sin^2\theta
$$

このとき，ノルムは0より大きく，$0\leq \theta \leq \pi$ では $\sin^2\theta \geq 0$ であるので

$$
||\pmb a\times \pmb b|| = ||\pmb a||\,||\pmb b||\sin \theta
$$


:::

<strong > &#9654;&nbsp; Key Takeaways</strong>

- 上記の定理は２つの３次現実ベクトルの外積のノルムは，２つの３次現実ベクトルが成す平行四辺形の面積と等しいことを意味している
- 外積を $\displaystyle\frac{1}{2}$ 倍すると，２つの３次現実ベクトルが成す三角形の面積となります．


::: {#exm- .custom_problem }
<br>

$$
\begin{align}
\pmb a &= (3, 4)\\
\pmb b &= (5, 2)
\end{align}
$$

と二次元ベクトルが与えられているとします．この２つのベクトルがなす三角形の面積は外積を応用すると以下のように計算できるはずです

$$
\begin{align}
\triangle ABO 
    &= \frac{1}{2}\sqrt{(0, 0, 3\times 2 - (4 \times 5))(0, 0, 3\times 2 - (4 \times 5))^T}\\
    &=  7
\end{align}
$$

- 上では二次元ベクトル $(x, y)$ を $(x, y, 0)$ とみなして計算しています
- ただし，これは外積の説明というよりかは $2$ 次正方行列の行列式がなぜ面積と対応するのかのほうが適切かも

実際に Pythonで計算してみると

::: {#fig-plot .center}

```{python}
import matplotlib.pyplot as plt
import numpy as np
# Define the two vectors
vector1 = np.array([3, 4])  # Vector 1 (x, y)
vector2 = np.array([5, 2])  # Vector 2 (x, y)

# Define the origin
origin = [0, 0]

# Create the plot
fig, ax = plt.subplots(figsize=(6, 6))

# Plot the vectors
ax.quiver(*origin, vector1[0], vector1[1], angles='xy', scale_units='xy', scale=1, color='r', label='Vector 1')
ax.quiver(*origin, vector2[0], vector2[1], angles='xy', scale_units='xy', scale=1, color='b', label='Vector 2')

# Plot the triangle
triangle_x = [0, vector1[0], vector2[0], 0]
triangle_y = [0, vector1[1], vector2[1], 0]
ax.fill(triangle_x, triangle_y, color='lightblue', alpha=0.5, label='Triangle')

# Set plot limits
ax.set_xlim(-1, max(vector1[0], vector2[0]) + 1)
ax.set_ylim(-1, max(vector1[1], vector2[1]) + 1)

# Add grid, labels, and legend
ax.grid()
ax.set_aspect('equal')
ax.set_xlabel('X-axis')
ax.set_ylabel('Y-axis')
ax.legend()

# Add title
ax.set_title('2D Vectors and Triangle')

# Show the plot
plt.show()
```
:::

```{python}
## compute area
from shapely import Polygon
coords = (origin, vector1, vector2)
polygon = Polygon(coords)

print(f"Area of triangle: {polygon.area}")
```


:::
---

### 外積の直交性

<div class="blog-custom-border" style="margin-top: 1rem; margin-bottom: 1rem;">
::: {#thm- .custom_problem }
<br>

２つの２次元実ベクトル $\pmb a, \pmb b$ について

$$
(\pmb a\times \pmb b, \pmb a) = (\pmb a\times \pmb b, \pmb b) = 0
$$

つまり，

$$
\begin{align}
\pmb a\times \pmb b \perp \pmb a\\
\pmb a\times \pmb b \perp \pmb a
\end{align}
$$

:::

</div>

::: {.callout-note collapse="false" icon=false}
## Proof

$$
\begin{align}
(\pmb a\times \pmb b, \pmb a)
    &=  \begin{vmatrix}
    a_1 & a_2 & a_3\\
    a_1 & a_2 & a_3\\
    b_1 & b_2 & b_3
    \end{vmatrix} = 0
\end{align}
$$

同様に

$$
\begin{align}
(\pmb a\times \pmb b, \pmb b)
    &=  \begin{vmatrix}
    b_1 & b_2 & b_3\\
    a_1 & a_2 & a_3\\
    b_1 & b_2 & b_3
    \end{vmatrix} = 0
\end{align}
$$

なお途中の式変形は行列式の性質「$|A| = 0 \Leftrightarrow \text{各行ベクトルが一次従属}$」を用いている．

:::

<strong > &#9654;&nbsp; Key Takeaways</strong>

- $\pmb a\times \pmb b$ のベクトルの方向は，$\pmb a$ から $\pmb b$ へ回転するときの右ねじが進む方向に対応すると言われる

::: {#fig-plot .center}

```{python}
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Define the vectors
a = np.array([3, 1, 0])  # Vector b
b = np.array([1, 2, 0])  # Vector a

# Compute the outer product (cross product)
outer_product = np.cross(a, b)

# Create a 3D plot
fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot vector a
ax.quiver(0, 0, 0, a[0], a[1], a[2], color='r', label='Vector a', arrow_length_ratio=0.1)

# Plot vector b
ax.quiver(0, 0, 0, b[0], b[1], b[2], color='b', label='Vector b', arrow_length_ratio=0.1)

# Plot the outer product vector
ax.quiver(0, 0, 0, outer_product[0], outer_product[1], outer_product[2], color='g', label='a × b', arrow_length_ratio=0.1)

# Plot the square
parallelogram_x = [0, a[0], a[0] + b[0], b[0], 0]
parallelogram_y = [0, a[1], a[1] + b[1], b[1], 0]
parallelogram_z = [0, a[2], a[2] + b[2], b[2], 0]
ax.plot_trisurf(parallelogram_x, parallelogram_y, parallelogram_z, color='lightblue', alpha=0.5, label='||a × b||')




# Set plot limits
max_range = max(np.linalg.norm(a), np.linalg.norm(b), np.linalg.norm(outer_product)) + 1
ax.set_xlim([-1, 6])
ax.set_ylim([-1, 6])
ax.set_zlim([-1, 6])

# Add labels and legend
ax.set_xlabel('X-axis')
ax.set_ylabel('Y-axis')
ax.set_zlabel('Z-axis')
ax.legend()

# Add title
ax.set_title('3D Vectors and Their Outer Product')

# Tilt the plot
ax.view_init(elev=30, azim=-60) 

# Show the plot
plt.show()
```

:::

## Appendix

<div class="blog-custom-border" style="margin-top: 1rem; margin-bottom: 1rem;">
::: {#lem-determinant .custom_problem }
<br>

第 $i$ 行が，２つの行ベクトルの和である行列の行列式は，他の行は同じで第 $i$ 行は各々のベクトルをとった行列の行列式となる．すなわち，

$$
\left|
\begin{array}{ccc}
a_{11} & \cdots & a_{1n} \\
\vdots &        & \vdots \\
b_{i1} + c_{i1} & \cdots & b_{in} + c_{in} \\
\vdots &        & \vdots \\
a_{n1} & \cdots & a_{nn}
\end{array}
\right|
= 
\left|
\begin{array}{ccc}
a_{11} & \cdots & a_{1n} \\
\vdots &        & \vdots \\
b_{i1} & \cdots & b_{in}\\
\vdots &        & \vdots \\
a_{n1} & \cdots & a_{nn}
\end{array}
\right|
+
\left|
\begin{array}{ccc}
a_{11} & \cdots & a_{1n} \\
\vdots &        & \vdots \\
c_{i1} & \cdots & c_{in} \\
\vdots &        & \vdots \\
a_{n1} & \cdots & a_{nn}
\end{array}
\right|
$$

:::

</div>

@lem-determinant より以下もわかります

$$
\left|
\begin{array}{ccc}
a_{11} & \cdots & a_{1n} \\
\vdots &        & \vdots \\
\lambda a_{i1} & \cdots & \lambda a_{in} \\
\vdots &        & \vdots \\
a_{n1} & \cdots & a_{nn}
\end{array}
\right|
= \lambda 
\left|
\begin{array}{ccc}
a_{11} & \cdots & a_{1n} \\
\vdots &        & \vdots \\
 a_{i1} & \cdots & a_{in} \\
\vdots &        & \vdots \\
a_{n1} & \cdots & a_{nn}
\end{array}
\right|\label{#eq-determinant-linear}
$$






### 余因子と行列式

<div class="blog-custom-border" style="margin-top: 1rem; margin-bottom: 1rem;">
::: {#def-cofactor .custom_problem }
**: 余因子(cofactor)**
<br>

$n$ 次の正方行列 $A = (a_{ij})$ から，その第 $i$ 行と第 $j$ 列を取り除いて得られる $(n-1)$ 次の正方行列を $A_{ij}$ と表記するとします．
このとき $a_{ij}$ の余因子 $\tilde{a}_{ij}$ は以下のように定義される

$$
\tilde{a}_{ij} = (-1)^{i+j}|A_{ij}|
$$

または

$$
\tilde{a}_{ij} = (-1)^{i+j} 
\left| 
\begin{array}{cccccc}
a_{11} & \cdots & a_{1(j-1)} & a_{1(j+1)} & \cdots & a_{1n} \\
\vdots &        & \vdots     & \vdots     &        & \vdots \\
a_{(i-1)1} & \cdots & \cdots & \cdots & \cdots & a_{(i-1)n} \\
a_{(i+1)1} & \cdots & \cdots & \cdots & \cdots & a_{(i+1)n} \\
\vdots &        & \vdots     & \vdots     &        & \vdots \\
a_{n1} & \cdots & a_{n(j-1)} & a_{n(j+1)} & \cdots & a_{nn}
\end{array}
\right|
$$

:::

</div>

::: {#exm- .custom_problem }
<br>

$$r
A = \left(\begin{array}{ccc}
1 & 2 & 0\\
3 & 5 & -1\\
4 & 6 & 7
\end{array}\right)
$$

について，$\tilde{a}_{11}, \tilde{a}_{12}, \tilde{a}_{13}$ はそれぞれ以下のように計算されます

$$
\begin{align}
\tilde{a}_{11} &= (-1)^2 \left(\begin{vmatrix}5 & -1\\6&7\end{vmatrix}\right) = 41\\
\tilde{a}_{12} &= (-1)^3 \left(\begin{vmatrix}3 & -1\\4&7\end{vmatrix}\right) = -25\\
\tilde{a}_{13} &= (-1)^4 \left(\begin{vmatrix}3 & 5\\4&6\end{vmatrix}\right) = -2
\end{align}
$$

:::
---



<div class="blog-custom-border" style="margin-top: 1rem; margin-bottom: 1rem;">
::: {#thm-cofactor-determinant .custom_problem }
**: 行列式の展開**
<br>

$$
a_{i1}\tilde a_{i1} + a_{i2}\tilde a_{i2} + \cdots + a_{in}\tilde a_{in} = |A|
$$

:::

</div>

<!--::: {.callout-note collapse="true" icon=false}-->
::: {.callout-note collapse="false" icon=false}
## Proof

与えられた行列 $A = (a_{ij})$ の第 $i$ 行は

$$
(a_{i1}, \cdots, a_{in}) = (a_{i1}, 0, \cdots, 0) + (0, a_{i2}, \cdots, 0) \cdots + (0, \cdots, 0, a_{in}) 
$$

と線型結合で表せるので，@lem-determinant より

$$
|A|
=
\left|
\begin{array}{cccc}
a_{11} &\cdots & \cdots & a_{1n} \\
\vdots & &       & \vdots \\
a_{11} & 0 & \cdots & 0 \\
\vdots &      &  & \vdots \\
a_{n1} &\cdots &\cdots & a_{nn}
\end{array}
\right|
+
\left|
\begin{array}{cccc}
a_{11} &\cdots & \cdots & a_{1n} \\
\vdots & &       & \vdots \\
0 & a_{12} & 0 \cdots & 0 \\
\vdots &      &  & \vdots \\
a_{n1} &\cdots &\cdots & a_{nn}
\end{array}
\right|
+ \cdots + 
\left|
\begin{array}{cccc}
a_{11} &\cdots & \cdots & a_{1n} \\
\vdots & &       & \vdots \\
0 & \cdots& \cdots 0 & a_{in} \\
\vdots &      &  & \vdots \\
a_{n1} &\cdots &\cdots & a_{nn}
\end{array}
\right|\label{#eq-additive}
$$

RHSの第 $j$ 番目の行列式の計算を考える．このとき，行を１つ交換するたびに行列式は $-1$ 倍されることから

$$
\left|
\begin{array}{ccccc}
a_{11} &\cdots &\cdots& \cdots & a_{1n} \\
\vdots & &   &    & \vdots \\
0 & \cdots  &a_{ij} & \cdots & 0 \\
\vdots &   &   &  & \vdots \\
a_{n1} &\cdots &\cdots &\cdots & a_{nn}
\end{array}
\right|
=
(-1)^{i-1}
\left|
\begin{array}{ccccc}
0 & \cdots  &a_{ij} & \cdots & 0 \\
a_{11} &\cdots &\cdots& \cdots & a_{1n} \\
\vdots & &   &    & \vdots \\
\vdots &   &   &  & \vdots \\
a_{n1} &\cdots &\cdots &\cdots & a_{nn}
\end{array}
\right|
$$

列を１つ交換するたびに行列式は $-1$ 倍されることから

$$
\left|
\begin{array}{ccccc}
0 & \cdots  &a_{ij} & \cdots & 0 \\
a_{11} &\cdots &\cdots& \cdots & a_{1n} \\
\vdots & &   &    & \vdots \\
\vdots &   &   &  & \vdots \\
a_{n1} &\cdots &\cdots &\cdots & a_{nn}
\end{array}
\right|
=
(-1)^{j-1}
\left|
\begin{array}{ccccc}
a_{ij} &0 & \cdots & \cdots & 0 \\
a_{1j} &a_{11} &\cdots & \cdots & a_{1n} \\
\vdots &\vdots & &       & \vdots \\
\vdots &\vdots &   &     & \vdots \\
a_{nj} &a_{n1} &\cdots  &\cdots & a_{nn}
\end{array}
\right|
$$

従って，

$$
\begin{align}
\left|
\begin{array}{ccccc}
a_{11} &\cdots &\cdots& \cdots & a_{1n} \\
\vdots & &   &    & \vdots \\
0 & \cdots  &a_{ij} & \cdots & 0 \\
\vdots &   &   &  & \vdots \\
a_{n1} &\cdots &\cdots &\cdots & a_{nn}
\end{array}
\right|
&= (-1)^{i+j-2}
a_{ij}
\left|
\begin{array}{cccc}
a_{11} &\cdots & \cdots & a_{1n} \\
\vdots & &       & \vdots \\
\vdots &   &     & \vdots \\
a_{n1} &\cdots  &\cdots & a_{nn}
\end{array}
\right|\\
&= (-1)^{i+j-2} a_{ij}|A_{ij}|\\
&= a_{ij}(-1)^{i+j-2}|A_{ij}|\\
&= a_{ij}\tilde a_{ij}
\end{align}
$$

\eqref{#eq-additive} より

$$
|A| = \sum_{j=1}^na_{ij}\tilde a_{ij}
$$

:::
